{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['python', 'парсинг']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_info(url, query):\n",
    "   \n",
    "    '''общий результат'''\n",
    "    table = {}\n",
    "    \n",
    "    '''достаем ссылки'''\n",
    "    urls = []\n",
    "    params = {\n",
    "        'search_query': 'python' or 'парсинг'\n",
    "    }\n",
    "    res = requests.get(url, params)\n",
    "    soup = BeautifulSoup(res.text, 'html.parser')\n",
    "    page1 = soup.find_all(class_='tm-pagination__page')\n",
    "    lastpage = str(page1[-1])\n",
    "    str1 = re.findall(r'[0-9]', lastpage)\n",
    "    \n",
    "    '''узнаем сколько страниц в поиске с помощью костыля'''\n",
    "    pages = 0\n",
    "    if len(str1) == 2:\n",
    "        pages += int(str1[0])\n",
    "    elif len(str1) == 4:\n",
    "        pages += int(str1[0] + str1[1])\n",
    "    elif len(str1) == 6:\n",
    "        pages += int(str1[0] + str1[1] + str1[2])\n",
    "    else:\n",
    "        print ('Too many lists')\n",
    "        \n",
    "    '''достаем все имеющиеся ссылки'''\n",
    "    for i in range(1, pages):\n",
    "        params['page'] = i\n",
    "        time.sleep(0.3)\n",
    "        news_blocks = soup.find_all(class_='tm-articles-list__item')\n",
    "        articles_intro = list(map(lambda x: x.find('div', class_='tm-article-body'), news_blocks))\n",
    "        a_list = list(map(lambda x: x.find('a').get('href'), articles_intro))\n",
    "        for link in a_list:\n",
    "            if 'https' not in link:\n",
    "                link = 'https://habr.com' + link\n",
    "                urls.append(link)\n",
    "            else:\n",
    "                urls.append(link)\n",
    "    \n",
    "    '''Достаем дату, описание и текст'''\n",
    "    date = []\n",
    "    title = []\n",
    "    text = []\n",
    "    \n",
    "    news_blocks = soup.find_all(class_='tm-articles-list__item')\n",
    "    for item in news_blocks:\n",
    "        try:\n",
    "            date.append(item.find_all('span', class_='tm-article-snippet__datetime-published').get_text())\n",
    "            title.append(item.find_all('h2', class_='tm-article-snippet__title tm-article-snippet__title_h2').get_text())\n",
    "            text.append(item.find_all('div', class_='article-formatted-body article-formatted-body_version-2').get_text())\n",
    "           \n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    table['date'] = date\n",
    "    table['title'] = title\n",
    "    table['url'] = urls\n",
    "    table_df = pd.DataFrame(table)\n",
    "    \n",
    "    return table_df\n",
    "    \n",
    "\n",
    "\n",
    "all_ = get_all_info('https://habr.com/ru/all/', 'python' or 'парсинг')\n",
    "alli = all_[0: 10]\n",
    "alli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "mails = ['xxx@x.ru', 'yyy@y.com']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = 'https://identityprotection.avast.com/v1/web/query/site-breaches/unauthorized-data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'Vaar-Version': '0',\n",
    "    'Vaar-Header-App-Product': 'hackcheck-web-avast',\n",
    "    'Vaar-Header-App-Product-Name': 'hackcheck-web-avast',\n",
    "    'Vaar-Header-App-Build-Version': '1.0.0'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.DataFrame(columns = {'email','date','site','title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for email in mails:\n",
    "    res = requests.post(request, json={'emailAddresses': [email]},headers = params)\n",
    "    info = json.loads(res.text) \n",
    "    if info:\n",
    "        for key in info['breaches'].keys():\n",
    "            title = extracted_data['breaches'][key]['description']\n",
    "            date = extracted_data['breaches'][key]['publishDate']\n",
    "            source = extracted_data['breaches'][key]['site']\n",
    "            site = extracted_data['breaches'][key]['site']\n",
    "            data = {'email':email,'date':date,'source':source,'title':title}\n",
    "            table = table.append(data,ignore_index=True)\n",
    "table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
